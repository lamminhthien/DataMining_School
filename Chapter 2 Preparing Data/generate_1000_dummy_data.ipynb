{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (13.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.2 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from faker) (3.10.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (1.1.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faker\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faker module from Python let you create up to million data (Need Strong PC to test) dummy data and create CSV file, to import to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transaction_date              Name Gender                    Email  \\\n",
      "0       2021-05-06   Monica Campbell      F       gwoodard@yahoo.com   \n",
      "1       2021-01-12  Elizabeth Chavez      F        sbryant@gmail.com   \n",
      "2       2021-06-30    Joshua Simpson      F  jacob15@mills-brown.biz   \n",
      "3       2021-06-17  Edward Dominguez      M  donaldwalker@harris.com   \n",
      "4       2021-01-26  Lauren Henderson      F         anne67@gmail.com   \n",
      "\n",
      "                  City Product_id  Amount_spent  \\\n",
      "0         North Denise   27733370         90.77   \n",
      "1       New Danieltown   33905051         78.56   \n",
      "2      East Davidmouth   02639925         57.32   \n",
      "3           Vargasland   93208840         24.70   \n",
      "4  Port Elizabethburgh   76983870         58.49   \n",
      "\n",
      "                                             Address    Color  \n",
      "0         83604 Denise Ville\\nMichaelhaven, NC 36771  #587f0b  \n",
      "1                   Unit 3399 Box 3536\\nDPO AP 21419  #d1b4f7  \n",
      "2  5086 Brian Mount Suite 445\\nSouth Andrew, TN 1...  #79fc0f  \n",
      "3            38698 Martin Lock\\nDenisebury, MA 11953  #e582be  \n",
      "4  78721 Kathryn Passage\\nLake Roberthaven, WV 18090  #e8bd61  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "from random import randrange\n",
    "from datetime import datetime\n",
    "\n",
    "# Number of data to test (I set 1010 for example)\n",
    "nr_of_customers = 1010\n",
    "\n",
    "# Initialize faker module\n",
    "fake = Faker()\n",
    "\n",
    "# This will be Object (JSON or we can call Multidimension array like php, in java we call hash map) to store all rows (sample)), in python we call \"Dictionary\"\n",
    "# In C# we call object\n",
    "customers = []\n",
    "\n",
    "\n",
    "for customers_id in range(nr_of_customers):\n",
    "\n",
    "    #  Transaction date duration (From time to time)\n",
    "    d1 = datetime.strptime(f'1/1/2021','%m/%d/%Y')\n",
    "    d2 = datetime.strptime(f'8/10/2021','%m/%d/%Y')\n",
    "\n",
    "\n",
    "    # Create date\n",
    "    transaction_date = fake.date_between(d1,d2)\n",
    "\n",
    "    # create customer's name (Unique)\n",
    "    name = fake.unique.name()\n",
    "    \n",
    "    # create gender\n",
    "    gender = random.choice([\"M\",\"F\"])\n",
    "\n",
    "    # Create Email\n",
    "    email = fake.unique.ascii_email()\n",
    "\n",
    "    # create city\n",
    "    city = fake.city()\n",
    "\n",
    "    # create product ID in 8-digit barcode\n",
    "    product_ID = fake.ean(length=8)\n",
    "\n",
    "    # create amount money spen\n",
    "    amount_spent = fake.pyfloat(right_digits=2,positive=True,min_value=1,max_value=100)\n",
    "\n",
    "    # create address\n",
    "    address = fake.address()\n",
    "\n",
    "    # create color\n",
    "    color = fake.color()\n",
    "\n",
    "    # add each rows (sample to dictionary (php) or can call multidimension array in PHP, like JSON Array in javascript)\n",
    "    customers.append([transaction_date,name,gender,email,city,product_ID,amount_spent,address,color])\n",
    "\n",
    "# add customers to data frame with feautures name (columns=...)\n",
    "customers_df = pd.DataFrame(customers,columns=['Transaction_date','Name','Gender','Email','City','Product_id','Amount_spent','Address','Color'])\n",
    "\n",
    "print(customers_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.to_csv('fakedata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Count distinct values, use <code>nunique</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df['City'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for city in customers_df['Gender'].unique():\n",
    "    i = i +1\n",
    "print(i)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f93bf75dccce2e11e3e0fe88cb893e67da4cec469989fda437a3a2f92a39a17"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('DataMining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
