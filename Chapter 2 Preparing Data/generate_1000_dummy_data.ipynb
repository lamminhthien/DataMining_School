{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (13.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.2 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from faker) (3.10.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (1.1.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lammi\\anaconda3\\envs\\datamining\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faker\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python snippets for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transaction_date               Name Gender                         Email  \\\n",
      "0       2021-05-08     Jeffrey Rogers      F  ygarrison@johnson-foster.com   \n",
      "1       2021-03-06       Carlos Jones      M               wprice@cole.com   \n",
      "2       2021-06-19   Tyler Harrington      M            esalinas@yahoo.com   \n",
      "3       2021-05-26  Jacqueline Foster      F     bradfordkaitlin@yahoo.com   \n",
      "4       2021-03-09      Joseph Flores      M        goodjonathan@yahoo.com   \n",
      "\n",
      "               City Product_id  Amount_spent  \n",
      "0     North William   98673322         77.13  \n",
      "1           Kimfort   50731244         59.20  \n",
      "2  West Beverlyland   86439756         37.12  \n",
      "3       North Steve   61661790         10.99  \n",
      "4          Halebury   04128083         34.29  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "from random import randrange\n",
    "from datetime import datetime\n",
    "\n",
    "nr_of_customers = 1010\n",
    "# Localization https://www.science.co.il/language/Locale-codes.php\n",
    "fake = Faker()\n",
    "\n",
    "customers = []\n",
    "\n",
    "for customers_id in range(nr_of_customers):\n",
    "\n",
    "    # Create transaction date\n",
    "    d1 = datetime.strptime(f'1/1/2021','%m/%d/%Y')\n",
    "    d2 = datetime.strptime(f'8/10/2021','%m/%d/%Y')\n",
    "\n",
    "    transaction_date = fake.date_between(d1,d2)\n",
    "\n",
    "    # create customer's name (Unique)\n",
    "    name = fake.unique.name()\n",
    "    \n",
    "    # create gender\n",
    "    gender = random.choice([\"M\",\"F\"])\n",
    "\n",
    "    # Create Email\n",
    "    email = fake.unique.ascii_email()\n",
    "\n",
    "    # create city\n",
    "    city = fake.city()\n",
    "\n",
    "    # create product ID in 8-digit barcode\n",
    "    product_ID = fake.ean(length=8)\n",
    "\n",
    "    #create amount spent \n",
    "    amount_spent = fake.pyfloat(right_digits=2,positive=True,min_value=1,max_value=100)\n",
    "\n",
    "    customers.append([transaction_date,name,gender,email,city,product_ID,amount_spent])\n",
    "\n",
    "customers_df = pd.DataFrame(customers,columns=['Transaction_date','Name','Gender','Email','City','Product_id','Amount_spent'])\n",
    "\n",
    "print(customers_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.to_csv('fakedata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Count distinct values, use <code>nunique</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df['City'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for city in customers_df['Gender'].unique():\n",
    "    i = i +1\n",
    "print(i)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f93bf75dccce2e11e3e0fe88cb893e67da4cec469989fda437a3a2f92a39a17"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('DataMining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
